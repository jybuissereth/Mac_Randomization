{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26b010e0-8151-426e-823e-4a19577b6ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nadjib Achir\n",
    "# some important imports \n",
    "import math\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07153d7c-481c-413a-a57f-86d4555b8647",
   "metadata": {},
   "source": [
    "# WiFi-de-randomization\n",
    "\n",
    "This document contains the code to match random MAC address coming from the same WiFi devices.\n",
    "\n",
    "Some of the important steps are :\n",
    "\n",
    "- STEP 1: Get the datasets\n",
    "    1. Download the Sapienza datase\n",
    "    2. Merge pcaps\n",
    "    3. Extract pcap fields using tshark\n",
    "- STEP 2: Randomization\n",
    "    1. Upload the dataset\n",
    "    2. Groupe all frames per MAC address\n",
    "    3. Remove Locally Administered MAC addresses\n",
    "    4. Deduce bursts lists\n",
    "    5. Randomize the MAC Addresses\n",
    "    6. Do timing sort\n",
    "    7. Save the new dataset and the ground truth\n",
    "- STEP 3: Create the time signature\n",
    "    - ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718bc9d7-7c85-490e-bc5f-6dff6de2382f",
   "metadata": {},
   "source": [
    "## STEP 1: Get the datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29f5ee2-c5d9-4a75-be33-95c33a703027",
   "metadata": {},
   "source": [
    "**1 - Download the Sapienza dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528b3e0a-25cb-47c5-8fd5-ea3385d813f9",
   "metadata": {},
   "source": [
    "Use the following link and login to download the datasets:\n",
    "\n",
    "https://crawdad.org/sapienza/probe-requests/20130910/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7f08b4-52f2-434a-816b-95e0138d2878",
   "metadata": {},
   "source": [
    "**2- Merge pcaps**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86b9700-0e47-4e3a-a3c2-021c41f77a05",
   "metadata": {},
   "source": [
    "Each dataset is composed of many .pcap files. We need to merge all the files. For example, to merge politics1\n",
    "dataset, use:\n",
    "\n",
    "```bash\n",
    "mergecap -w politics1.pcap probes-2013-02-22.pcap*\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f37bed-835a-4e99-b500-2257630d4ddd",
   "metadata": {},
   "source": [
    "**3- Extract pcap fields using tshark**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706925c1-61c5-4358-820e-d3a98b75d08d",
   "metadata": {},
   "source": [
    "Using the following command we can extract from the dataset only relevent informations. Here I kept as much as possible informations from the original dataset, in case we do more analysis in the future. However, if we focus only on timing attack, we can only keep the timestamp. In this example, we collect many fields from each **probe_request** frame:\n",
    "\n",
    "```bash\n",
    "chmod +x tshark_extraction.sh\n",
    "./tshark_extraction.sh dataset_name\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe573a6-92cf-466a-8e12-6eaade34e047",
   "metadata": {},
   "source": [
    "## STEP 2: Randomization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "524f7ec8-b578-4e1c-b7b4-62bba08d257b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some useful imports \n",
    "from collections import defaultdict\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f9abecb9-36f4-440e-8b93-bb5f0bd245c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset folder:  ./politics1/politics1_dataset\n",
      "dataset randomized path:  ./politics1/politics1_randomized_p4_btf0.01_dataset\n",
      "dataset randomized path label:  ./politics1/politics1_randomized_p4_btf0.01_dataset_label\n"
     ]
    }
   ],
   "source": [
    "BURST_TIME_FRAME = 0.01 # the maximum duration of a burst in time (second)\n",
    "p = 4 # change the mac address every p bursts\n",
    "\n",
    "#\n",
    "dataset = 'politics1'\n",
    "\n",
    "#\n",
    "dataset_file_path = './' + dataset + '/' + dataset + '_dataset'\n",
    "print('dataset folder: ', dataset_file_path)\n",
    "isExist = os.path.exists(dataset_file_path)\n",
    "assert isExist == True, 'The dataset does not exist'\n",
    "\n",
    "#\n",
    "dataset_randomized_path = './' + dataset + '/' + dataset + '_randomized_p' + str(p) + '_btf' + str(BURST_TIME_FRAME) + '_dataset'\n",
    "print('dataset randomized path: ', dataset_randomized_path)\n",
    "\n",
    "#\n",
    "dataset_randomized_label_path = dataset_randomized_path + '_label'\n",
    "print('dataset randomized path label: ', dataset_randomized_label_path)\n",
    "\n",
    "#\n",
    "sanitization = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9fc4de-2628-409f-83fd-36461e96284c",
   "metadata": {},
   "source": [
    "**1- Upload the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d72445d3-5b9d-4ca5-a96f-3f35b3fe1e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function used to load the frames\n",
    "def load_dataset(dataset_path: str) -> list:\n",
    "    \"\"\"\n",
    "    Read dataset from disk\n",
    "    \"\"\"\n",
    "    frames = []\n",
    "    with open(dataset_path) as data:\n",
    "        for frame in data:\n",
    "            frame_tmp = frame.strip('\\n').split(';')\n",
    "            frames.append(frame_tmp)\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec9d9859-7507-47ef-a8df-6444fde52f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the frames\n",
    "frames = load_dataset(dataset_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ebc117d5-9768-4d32-8925-c5ac9c962e58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1189482"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741f5969-e85d-449a-bdf0-0b0cd69cf221",
   "metadata": {},
   "source": [
    "**2- Groupe all frames per MAC address**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb4e3662-c5d1-4ab6-a8a8-7e0e02317edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function group all the frames with the same MAC address into one single dictionary\n",
    "def separete_macs(frames: list) -> dict:\n",
    "    \"\"\"\n",
    "    Group same MAC address\n",
    "    \"\"\"\n",
    "    macs = defaultdict(list)\n",
    "    for frame in frames:\n",
    "        fm = [frame[0]] + frame[2:]\n",
    "        macs[frame[1]].append(fm)\n",
    "    return macs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f0942ba-80c6-4358-a3a4-589fba2ff969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we create a dictionary per mac address with all frames belonging to the same mac address\n",
    "mac_dict = separete_macs(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ad54438-bde2-4e13-9b7e-8da2e04a2c0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16691"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mac_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe888d0-ad44-4351-8bea-2c13262ec0d1",
   "metadata": {},
   "source": [
    "**3- Remove Locally Administered MAC addresses**\n",
    "\n",
    "![image.png](https://upload.wikimedia.org/wikipedia/commons/9/94/MAC-48_Address.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89415fbe-ab1d-4335-b486-34102e5016aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function remove the Locally Administered MAC addresses \n",
    "# A locally administered address is assigned to a device by \n",
    "# a network administrator, overriding the burned-in address. \n",
    "# Here the second-least-significant bit of the first octet of \n",
    "# the address is a 1.\n",
    "# There are 4 ranges of Locally Administered Address Ranges \n",
    "# that can be used on a local network:\n",
    "# x2-xx-xx-xx-xx-xx\n",
    "# x6-xx-xx-xx-xx-xx\n",
    "# xA-xx-xx-xx-xx-xx\n",
    "# xE-xx-xx-xx-xx-xx\n",
    "def verify_randomized(mac_dict):\n",
    "    count = 0\n",
    "    for mac in mac_dict.copy():\n",
    "        if  mac != '' and bin(int(mac[0:2], 16))[2:].zfill(8)[-2] == '1':\n",
    "            count += 1\n",
    "            del mac_dict[mac]\n",
    "    print(\"Locally Administered Removed MAC Address: {}%\".format((count * 100) / len(mac_dict)))\n",
    "    return mac_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f93fdf97-28f8-43fa-86d9-90134ffb3817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Locally Administered Removed MAC Address: 0.095952023988006%\n"
     ]
    }
   ],
   "source": [
    "# remove the Locally Administered MAC addresses\n",
    "mac_dict = verify_randomized(mac_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e0983971-35ea-47bd-a4ba-085ebe5967ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16675"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mac_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "daa32aac-c796-40bd-af8d-73f1f8594864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete frames. No more used\n",
    "del frames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5145a865-3abd-4c70-8b69-55248165484c",
   "metadata": {},
   "source": [
    "**4- Deduce bursts lists**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "30f6114a-557b-49dd-8f9b-44c69fca1938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function transforme a list of frames belonging to the same MAC address into a list of burst.\n",
    "# Each burst is also a list of frames belonging to the same burst (all frames alre within the same BURST_TIME_FRAME)\n",
    "def group_bursts(time_frames: list) -> list:\n",
    "    \"\"\"\n",
    "    Create burst lists based in burst time size\n",
    "    \"\"\"\n",
    "    # list of bursts\n",
    "    bursts = []\n",
    "    # list of frames of one burst\n",
    "    burst = []\n",
    "    \n",
    "    i = 0\n",
    "    # while not processign all frames belonging to the same MAC address\n",
    "    while i < len(time_frames):\n",
    "        # add the first frame to the burst\n",
    "        if len(burst) == 0:\n",
    "            burst.append(time_frames[i])\n",
    "            i += 1\n",
    "        else:\n",
    "            # if the time separating two consecutive frames is less than a BURST_TIME_FRAME\n",
    "            if float(time_frames[i][0]) - float(burst[0][0]) <= BURST_TIME_FRAME:\n",
    "                # add the current frame to the current burst\n",
    "                burst.append(time_frames[i])\n",
    "                i += 1\n",
    "            elif len(burst) > 0:\n",
    "                # add the burst list to the list of bursts.\n",
    "                # do not add empty burst\n",
    "                # remove burst less than two frames ??? do not know if useful yest!!!\n",
    "                bursts.append(burst)\n",
    "                # initialize the burst list to empty\n",
    "                burst = []\n",
    "            else:\n",
    "                # initialize the burst list to empty\n",
    "                burst = []\n",
    "        # if we processed all the burst. Add the last burst to the list of bursts\n",
    "        if i >= len(time_frames):\n",
    "            # check if we have at least 2 frames in that burst\n",
    "            if len(burst) > 1:\n",
    "                bursts.append(burst)\n",
    "            burst = []\n",
    "    return bursts\n",
    "\n",
    "# this function process all MAC addresses\n",
    "def select_bursts(mac_dict: dict) -> dict:\n",
    "    \"\"\"\n",
    "    For each MAC return a list with burst\n",
    "    \"\"\"\n",
    "    bursts = defaultdict(list)\n",
    "    for mac in mac_dict:\n",
    "        if len(mac_dict[mac]) >= 1:\n",
    "            bursts[mac] = group_bursts(mac_dict[mac])\n",
    "    return bursts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a771b2ff-a41f-452d-ba97-c96bb85b7935",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16675"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# return a dicionary of bursts \n",
    "burst_set = select_bursts(mac_dict)\n",
    "len(burst_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e44734-c4fe-48f9-aa22-2a1d3803a892",
   "metadata": {},
   "source": [
    "**5- Randomize the MAC Addresses**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "54c39356-ceb5-466e-9660-651296f049a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function generate a new mac address\n",
    "def generate_mac() -> str:\n",
    "    # First byte:\n",
    "    new_mac = '%02X' % int(bin(random.randint(0, 63)) + '11', 2) + ':'\n",
    "\n",
    "    # Next 4 bytes:\n",
    "    for i in range(4):\n",
    "        new_mac += '%02X' % random.randint(0, 255) + ':'\n",
    "\n",
    "    # Last byte:\n",
    "    new_mac += '%02X' % random.randint(0, 255)\n",
    "    return new_mac\n",
    "\n",
    "\n",
    "# This function randomize the mac address p bursts per p bursts.\n",
    "def randomize_mac(burst_set: dict, number_of_devices: int, minimum_burst_len: int = 100) -> tuple:\n",
    "    bursts = defaultdict(list)\n",
    "    ground_truth = {}\n",
    "    dev_number = 0\n",
    "\n",
    "    # for each mac address\n",
    "    for mac in burst_set:\n",
    "        # check if the number of bursts is greater then a given number of bursts.\n",
    "        if len(burst_set[mac]) > minimum_burst_len:\n",
    "            # if we reached the number of devices\n",
    "            if dev_number >= number_of_devices:\n",
    "                print(dev_number)\n",
    "                # return the bursts and the grount truth\n",
    "                return bursts, ground_truth\n",
    "            # increase the number of devices processed by one\n",
    "            dev_number += 1\n",
    "            # change the mac addresses every p bursts ...\n",
    "            for i in range(0, len(burst_set[mac]), p):\n",
    "                # generate a new mac address\n",
    "                new_mac = generate_mac()\n",
    "                # associate the new mac address with the real mac address\n",
    "                ground_truth[new_mac] = mac\n",
    "                # extract the set of burst and affect them to the generated mac address\n",
    "                for burst in burst_set[mac][i:i + p]:\n",
    "                    bursts[new_mac].append(burst)\n",
    "    return bursts, ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9c96a4b0-2c80-4ccf-8d97-77b9d336873b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "minimum_burst_len = 0\n",
    "random_dataset, ground_truth = randomize_mac(burst_set, len(mac_dict), minimum_burst_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2c66c3-b6c3-45ed-90d4-d743cd973963",
   "metadata": {},
   "source": [
    "**6- Do timing sort**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0fe902e1-9e37-4221-8bea-9d15780eb339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function sort the frames according to time whitin each burst\n",
    "def sort_timing(bursts):\n",
    "    frames_sorted = []\n",
    "    for mac in bursts:\n",
    "        for burst in bursts[mac]:\n",
    "            for frame in burst:\n",
    "                frames_sorted.append([float(frame[0])] + [mac] + frame[1:])\n",
    "    return sorted(frames_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1d76bb8c-df17-4511-be9e-2ee23900686f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort the frames\n",
    "sorted_frames = sort_timing(random_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d387f682-ba5a-43a4-80b7-42044529852e",
   "metadata": {},
   "source": [
    "**7- Save the new dataset and the ground truth**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1cc1a554-2d0e-4d2b-857c-9d03a0088bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function save the new dataset\n",
    "def save_dataset(frames: list, dataset_path: str) -> None:\n",
    "    with open(dataset_path, 'w') as file:\n",
    "        for frame in frames:\n",
    "            str_frame = ''\n",
    "            for field in frame:\n",
    "                str_frame += str(field) + ';'\n",
    "            file.write(str_frame + '\\n')\n",
    "\n",
    "# This function save the ground truth dictionary\n",
    "def save_ground_truth(ground_truth, dataset_path: str):\n",
    "    with open(dataset_path, 'w') as file:\n",
    "        for key, val in ground_truth.items():\n",
    "            file.write(str(key) + ';' + str(val) + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "83ac26d0-92c8-4ead-a482-837f532a3cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dataset(sorted_frames, dataset_randomized_path)\n",
    "save_ground_truth(ground_truth, dataset_randomized_label_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2100bda-470d-4e9d-986b-e8d845422485",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
